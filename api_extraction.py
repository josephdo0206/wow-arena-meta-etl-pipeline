# -*- coding: utf-8 -*-
"""Course_8_Capstone_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mdr8Q7lkc-5K-e2QRHioVwfHh6acswHN
"""

import requests

# 1. Your Credentials (keep the quotation marks!)
client_id = "YOUR_CLIENT_ID_HERE"
client_secret = "YOUR_CLIENT_SECRET_HERE"

# 2. Set up the request to Blizzard's Authentication Server
url = "https://us.battle.net/oauth/token"
body = {"grant_type": "client_credentials"}

# 3. Send the request
response = requests.post(url, data=body, auth=(client_id, client_secret))

# 4. Check the results
if response.status_code == 200:
    access_token = response.json().get("access_token")
    print("SUCCESS. Mainframe breached. üõ°Ô∏è")
    print(f"Your temporary Access Token is: {access_token[:10]}... (hidden for security)")
else:
    print(f"ACCESS DENIED. Error code: {response.status_code}")

# 5. Set the target endpoint (3v3 Bracket)
# Note: Season 36 represents the current retail season
season_id = 36
url = f"https://us.api.blizzard.com/data/wow/pvp-season/{season_id}/pvp-leaderboard/3v3"

# 6. Pass your VIP badge (Token) and the region namespace
headers = {
    "Authorization": f"Bearer {access_token}"
}

# The namespace tells Blizzard we want Retail US servers, not Classic
params = {
    "namespace": "dynamic-us",
    "locale": "en_US"
}

# 7. Extract the data
response = requests.get(url, headers=headers, params=params)
ladder_data = response.json()

# 8. Inspect the very first player on the leaderboard
print(ladder_data['entries'][0])

import pandas as pd

# 1. Create an empty list to hold our clean rows of data
clean_ladder = []

# 2. Loop through every single player in the raw JSON entries we downloaded
for player in ladder_data['entries']:

    # 3. Extract exactly what we want, digging into the nested dictionaries
    row = {
        'rank': player.get('rank'),
        'name': player['character'].get('name'),
        'realm': player['character']['realm'].get('slug'),
        'faction': player['faction'].get('type'),
        'rating': player.get('rating'),
        'wins': player['season_match_statistics'].get('won'),
        'losses': player['season_match_statistics'].get('lost')
    }

    # 4. Add this clean row to our list
    clean_ladder.append(row)

# 5. Convert our list of clean rows into a powerful Pandas DataFrame
df_ladder = pd.DataFrame(clean_ladder)

# 6. Inspect the first 5 rows of our new, clean database!
df_ladder.head()

# 1. Create a list to hold the new class data
class_data = []

# 2. Loop through ONLY the first 5 players to test the logic
for index, row in df_ladder.head(5).iterrows():

    # The Profile API requires names and realms to be lowercase
    name = row['name'].lower()
    realm = row['realm'].lower()

    # 3. The new target: The Character Profile API
    profile_url = f"https://us.api.blizzard.com/profile/wow/character/{realm}/{name}"
    profile_params = {
        "namespace": "profile-us",  # Note the namespace changes to 'profile'
        "locale": "en_US"
    }

    # 4. Send the request with your existing token
    response = requests.get(profile_url, headers=headers, params=profile_params)

    # 5. Extract the Class and Spec if the profile exists
    if response.status_code == 200:
        char_info = response.json()
        player_class = char_info['character_class'].get('name')
        player_spec = char_info['active_spec'].get('name')
    else:
        # Sometimes players transfer realms, causing a 404 error
        player_class = "Unknown"
        player_spec = "Unknown"

    class_data.append({
        'name': row['name'],
        'class': player_class,
        'spec': player_spec
    })

# 6. Convert the new data to a DataFrame
df_classes = pd.DataFrame(class_data)

# 7. THE MERGE: Join the class data with our original ladder data based on their Name
df_final = pd.merge(df_ladder.head(5), df_classes, on='name')

# Inspect the final product
df_final

import time # We need this to pause slightly so Blizzard doesn't block us

class_data = []
target_players = 1000 # Let's pull the Top 1000 players

print(f"Commencing mass extraction of Top {target_players} players...")

# Loop through the first 1000 rows
for index, row in df_ladder.head(target_players).iterrows():

    # We use .encode('utf-8') to help handle some (but not all) special characters
    name = row['name'].lower()
    realm = row['realm'].lower()

    profile_url = f"https://us.api.blizzard.com/profile/wow/character/{realm}/{name}"
    profile_params = {
        "namespace": "profile-us",
        "locale": "en_US"
    }

    response = requests.get(profile_url, headers=headers, params=profile_params)

    if response.status_code == 200:
        char_info = response.json()
        player_class = char_info['character_class'].get('name')
        player_spec = char_info['active_spec'].get('name')
    else:
        player_class = "Unknown"
        player_spec = "Unknown"

    class_data.append({
        'name': row['name'],
        'class': player_class,
        'spec': player_spec
    })

    # Print progress every 100 players so you know it hasn't frozen
    if (index + 1) % 100 == 0:
        print(f"Successfully processed {index + 1} players...")

    # Sleep for a tiny fraction of a second to respect Blizzard's API limits
    time.sleep(0.05)

print("Extraction complete. Merging data...")

# Convert and Merge
df_classes = pd.DataFrame(class_data)
df_final = pd.merge(df_ladder.head(target_players), df_classes, on='name')

# Save the final product to your Colab files as a CSV!
df_final.to_csv('tww_s3_top1000_meta.csv', index=False)
print("FILE SAVED: tww_s3_top1000_meta.csv")

import time

class_data = []
target_players = 1000

print(f"Commencing mass extraction of Top {target_players} players...")

for index, row in df_ladder.head(target_players).iterrows():
    name = row['name'].lower()
    realm = row['realm'].lower()

    profile_url = f"https://us.api.blizzard.com/profile/wow/character/{realm}/{name}"
    profile_params = {
        "namespace": "profile-us",
        "locale": "en_US"
    }

    response = requests.get(profile_url, headers=headers, params=profile_params)

    if response.status_code == 200:
        char_info = response.json()

        # THE FIX: Safely stringing .get() methods together.
        # If the first dictionary is missing, it defaults to an empty dict {} so the second .get() doesn't crash.
        player_class = char_info.get('character_class', {}).get('name', 'Unknown')
        player_spec = char_info.get('active_spec', {}).get('name', 'Unknown')
    else:
        player_class = "Unknown"
        player_spec = "Unknown"

    class_data.append({
        'name': row['name'],
        'class': player_class,
        'spec': player_spec
    })

    if (index + 1) % 100 == 0:
        print(f"Successfully processed {index + 1} players...")

    time.sleep(0.05)

print("Extraction complete. Merging data...")

# Convert and Merge
df_classes = pd.DataFrame(class_data)
df_final = pd.merge(df_ladder.head(target_players), df_classes, on='name')

# Save the final product to your Colab files as a CSV!
df_final.to_csv('tww_s3_top1000_meta.csv', index=False)
print("FILE SAVED: tww_s3_top1000_meta.csv")